[["week-15-more-regression.html", "6 Week 15: More regression", " 6 Week 15: More regression Written by Margriet Groen (partly adapted from Winter (2020)) Previously, we looked at logistic regression in the context of a binomial outcome variable, that is, a two-level variable such as correct vs. incorrect, or looking to the left vs. the right. Poisson regression is another type of generalized linear model that is particularly useful for count data. ## Lectures The lecture material for this week follows the recommended chapters in Winter (2020) -- see under 'Reading' below -- and is presented below: * [**Poisson regression (~28 min)**](https://web.microsoftstream.com/video/62a8baeb-c951-4cf0-ace4-65916331b891) ## Reading ### Winter (2020) [**Link**](https://eu.alma.exlibrisgroup.com/leganto/public/44LAN_INST/citation/83408786230001221?auth=SAML) **Chapter 13** provides a clear introduction to Poisson regression and its implementation in R. ## Pre-lab activities After having watched the lectures and read the textbook chapters youâ€™ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly. ### Pre-lab activity 1: Getting a feel for Poisson data To get a feel for Poisson data, we'll use the `rpois()` function to generate random data that is Poisson-distributed. `rpois()` needs two bits of information: lambda, and how many numbers you want to generate. As usual, before we get stuck in we need to set up a few things. > **TASK**: Add code to clear the environment. **HINT**: `rm(list=ls())` Next we need to tell R which libraries to use. For this pre-lab activity, we just need the `tidyverse` library. > **TASK**: Add code to load relevant libraries. **HINT**: `library()` Ok, now let's play around with different lambdas to get a feel for the Poisson distribution. > **TASK**: Copy the code below to your script and run it. Then change the value of `lambda` in the `rpois()` function and see how the distribution changes. ```r lambda2 **TASK**: Add code to clear the environment. **HINT**: `rm(list=ls())` Next we need to tell R which libraries to use. We need `broom`, `tidyverse`, `MASS` and `pscl`. > **TASK**: Add code to load relevant libraries. **HINT**: `library()` Finally, read in the two data files (`lynott_connell_2009_modality.csv` and `ELP_full_length_frequency.csv`) and have a look at them. > **TASK**: Add code to read in the two data files and have a look at them. **HINT**: Use the `read_csv()` and `head()` functions. **QUESTION 1**: Which variables do you need to address the research question? #### Step 2: A bit of data wrangling We need to combine the information in the data files to be able to do any analyses. We can use a 'join' to do this. Have a look at the online book by Hadley Wickam and Gareth Grolemund ([**here**](https://r4ds.had.co.nz/relational-data.html?q=left_join#mutating-joins)) to remind yourself what a 'join' is. In particular, have a look at the `inner_join()` and the `left_join()`. **QUESTION 2**: Which 'join' is most appropriate, the `inner_join()` or the `left_join()`? Also, does it matter which datafile you specify as x and which one as y? If so, why does it matter? > **TASK**: Add code to join the two data files and store the resulting table in an object called `both`. Try out the different joins and use `head()` to inspect the result. **HINT**: You should end up with a table that has 423 observations of at least 8 variables. Next, we want to select only the variables we need. We want to use the `select()` function from `dplyr`. Because the MASS library is also loaded and that library also contains a `select()` function, we need to tell R specifically to use the one from `dplyr`. You can do this by using `dpply::`, like this: ```r both **TASK**: Add the code above to your script and run it. Finally, to apply Poisson regression, we need the frequency variable as positive integers. > **TASK**: Use the code below to transform the frequency variable to raw values. Don't forget to add it to your script and run it. ```r both **TASK**: Add code to make scatterplots with Freq on the y axis and each of the sensory modality ratings on the respective x axis. To be able to see more easily what is going on, limit the y-axis to values between 0 and 20000. **HINT**: Make 5 different scatterplots using `ggplot()` with`geom_point()` and `geom_smooth()`. You can use `ylim()` to limit the values on the y-axis. **QUESTION 4**: What do you conclude from the scatterplots? #### Step 4: The regression model We are going to fit a Poisson regression model with `Taste`, `Smell`, `Touch`, `Sight` and `Sound` as predictors (all of these are continuous rating scales). > **TASK**: Fit a Poisson regression model for 'Freq' as a function of 'Taste', 'Smell', 'Touch', 'Sight' and 'Sound'. **HINT**: Use the `glm()` function with `family = poisson`. **QUESTION 5**: How do you interpret the output of the Poisson regression? #### Step 5: Overdispersion In the lecture we saw that it is possible that the variance is larger than theoretically expected for a given lambda. If this happens, we are dealing with what's called 'overdispersion'. You can compensate for this by using a variant of Poisson regression that is called 'negative binomial regression'. In negative binomial regression the variance is uncouples from the mean. > **TASK**: Fit a negative binomial regression model for 'Freq' as a function of 'Taste', 'Smell', 'Touch', 'Sight' and 'Sound'. **HINT**: Use the `glm.nb()` function. Next, check whether there is significant overdispersion by performing a likelihood ratio test, comparing the likelihood of the negative binomial model against the likelihood of the corresponding Poisson model. > **TASK**: Use the `odTest()` function to perform an 'overdispersion' test. **QUESTION 6**: What do you conclude from the results of the overdispersion test? **QUESTION 7**: How do you interpret the negative binomial regression output? Do English speakers use visual adjectives more frequently? What about smell adjectives in comparison? ## Answers When you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. **Remember**, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. **Actively engaging** with the material is the way to learn these analysis skills, not by looking at someone else's completed code... The answers to the questions and the script containing the code will be available after the lab session has taken place. You can download the R-script that includes the relevant code here: [402_wk15_labAct1_withAnswers.R](files/week15/402_wk15_labAct1_withAnswers.R). 1. Which variables do you need to address the research question? **Our dependent variable is word frequency, so we need a variable that tells us how frequent words are. This information is contained in the English Lexicon Project data file, variable Log10Freq. The sensory modality ratings as reported in the in the data file supplied by Lynott and Connell (2009) are our predictors. That means we need the variables 'Sight', 'Touch', 'Sound', 'Taste', and 'Smell'. You also need a variable that is common across the two files to help with merging them together (i.e., `by =` ), this would be 'Word'.** 2. Which 'join' is most appropriate, the `inner_join()` or the `left_join()`? Also, does it matter which datafile you specify as x and which one as y? If so, why does it matter? **A `left_join()` keeps all observations in table x, adding the information from table y for those observations. That means that it does matter which table you specify as x and which one as y. ELP contains word frequencies for many more words than we have sensory modality ratings for (in lyn). When specifying ELP as x, you keep 33075 rows, adding a lot of NAs for words we do not have sensory modality ratings for. Therefore it makes more sense to specify lyn as x, and add the word frequency information for the words we have sensory modality ratings for. An `inner_join()` matches pairs of observations whenever their keys are equal, and unmatched rows are not included in the result. This means that generally inner joins are not appropriate because it is too easy to lose observations.** 3. What does this line of code do. Write a comment to summarise its function. ```r both "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
