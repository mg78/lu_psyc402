<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Step 5: The regression model ———————– | Analysing and Interpreting Psychological Data II - PSYC402</title>
  <meta name="description" content="Course content for PSYC402 at Lancaster University" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Step 5: The regression model ———————– | Analysing and Interpreting Psychological Data II - PSYC402" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course content for PSYC402 at Lancaster University" />
  <meta name="github-repo" content="mg78/lu_psyc402" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Step 5: The regression model ———————– | Analysing and Interpreting Psychological Data II - PSYC402" />
  
  <meta name="twitter:description" content="Course content for PSYC402 at Lancaster University" />
  

<meta name="author" content="Margriet Groen and Rob Davies" />


<meta name="date" content="2022-02-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="week-13-more-on-interactions.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PSYC402 - Analysing and Interpreting Psychological Data II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Intro</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#analysis-labs-and-pre-lab-work"><i class="fa fa-check"></i><b>1.1</b> Analysis labs and ‘pre-lab work’</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><i class="fa fa-check"></i><b>2</b> Week 11: Recap of the linear model and practising data-wrangling in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#lectures"><i class="fa fa-check"></i><b>2.1</b> Lectures</a></li>
<li class="chapter" data-level="2.2" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#reading"><i class="fa fa-check"></i><b>2.2</b> Reading</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#miller-haden-2013"><i class="fa fa-check"></i><b>2.2.1</b> Miller &amp; Haden (2013)</a></li>
<li class="chapter" data-level="2.2.2" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#winter-2020"><i class="fa fa-check"></i><b>2.2.2</b> Winter (2020)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#pre-lab-activities"><i class="fa fa-check"></i><b>2.3</b> Pre-lab activities</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#pre-lab-activity-1-visualising-the-regression-line"><i class="fa fa-check"></i><b>2.3.1</b> Pre-lab activity 1: Visualising the regression line</a></li>
<li class="chapter" data-level="2.3.2" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#pre-lab-activity-2-data-wrangling-in-r"><i class="fa fa-check"></i><b>2.3.2</b> Pre-lab activity 2: Data-wrangling in R</a></li>
<li class="chapter" data-level="2.3.3" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#pre-lab-activity-3-getting-ready-for-the-lab-class"><i class="fa fa-check"></i><b>2.3.3</b> Pre-lab activity 3: Getting ready for the lab class</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#lab-activities"><i class="fa fa-check"></i><b>2.4</b> Lab activities</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#lab-activity-1-interpreting-and-reporting-results"><i class="fa fa-check"></i><b>2.4.1</b> Lab activity 1: Interpreting and reporting results</a></li>
<li class="chapter" data-level="2.4.2" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#lab-activity-2-conducting-simple-and-multiple-regression"><i class="fa fa-check"></i><b>2.4.2</b> Lab activity 2: Conducting simple and multiple regression</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#answers"><i class="fa fa-check"></i><b>2.5</b> Answers</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#lab-activity-1-interpreting-and-reporting-results-1"><i class="fa fa-check"></i><b>2.5.1</b> Lab activity 1: Interpreting and reporting results</a></li>
<li class="chapter" data-level="2.5.2" data-path="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html"><a href="week-11-recap-of-the-linear-model-and-practising-data-wrangling-in-r.html#lab-activity-2-conducting-simple-and-multiple-regression-1"><i class="fa fa-check"></i><b>2.5.2</b> Lab activity 2: Conducting simple and multiple regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html"><i class="fa fa-check"></i><b>3</b> Week 12: Categorical predictors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#lectures-1"><i class="fa fa-check"></i><b>3.1</b> Lectures</a></li>
<li class="chapter" data-level="3.2" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#reading-1"><i class="fa fa-check"></i><b>3.2</b> Reading</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#blogpost-by-professor-dorothy-bishop"><i class="fa fa-check"></i><b>3.2.1</b> Blogpost by Professor Dorothy Bishop</a></li>
<li class="chapter" data-level="3.2.2" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#winter-2020-1"><i class="fa fa-check"></i><b>3.2.2</b> Winter (2020)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#pre-lab-activities-1"><i class="fa fa-check"></i><b>3.3</b> Pre-lab activities</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#pre-lab-activity-1-data-wrangling-in-r"><i class="fa fa-check"></i><b>3.3.1</b> Pre-lab activity 1: Data-wrangling in R</a></li>
<li class="chapter" data-level="3.3.2" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#pre-lab-activity-2-getting-ready-for-the-lab-class"><i class="fa fa-check"></i><b>3.3.2</b> Pre-lab activity 2: Getting ready for the lab class</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#lab-activities-1"><i class="fa fa-check"></i><b>3.4</b> Lab activities</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#lab-activity-1-combining-a-continuous-and-a-categorical-predictor-in-a-resssion-model"><i class="fa fa-check"></i><b>3.4.1</b> Lab activity 1: Combining a continuous and a categorical predictor in a resssion model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#answers-1"><i class="fa fa-check"></i><b>3.5</b> Answers</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="week-12-categorical-predictors.html"><a href="week-12-categorical-predictors.html#lab-activity-1-combining-a-continuous-and-a-categorical-predictor-in-a-resssion-model-1"><i class="fa fa-check"></i><b>3.5.1</b> Lab activity 1: Combining a continuous and a categorical predictor in a resssion model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-13-more-on-interactions.html"><a href="week-13-more-on-interactions.html"><i class="fa fa-check"></i><b>4</b> Week 13: More on interactions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="week-13-more-on-interactions.html"><a href="week-13-more-on-interactions.html#lectures-2"><i class="fa fa-check"></i><b>4.1</b> Lectures</a></li>
<li class="chapter" data-level="4.2" data-path="week-13-more-on-interactions.html"><a href="week-13-more-on-interactions.html#reading-2"><i class="fa fa-check"></i><b>4.2</b> Reading</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="week-13-more-on-interactions.html"><a href="week-13-more-on-interactions.html#winter-2020-2"><i class="fa fa-check"></i><b>4.2.1</b> Winter (2020)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="week-13-more-on-interactions.html"><a href="week-13-more-on-interactions.html#pre-lab-activities-2"><i class="fa fa-check"></i><b>4.3</b> Pre-lab activities</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="week-13-more-on-interactions.html"><a href="week-13-more-on-interactions.html#pre-lab-activity-1-data-wrangling-in-r-1"><i class="fa fa-check"></i><b>4.3.1</b> Pre-lab activity 1: Data-wrangling in R</a></li>
<li class="chapter" data-level="4.3.2" data-path="week-13-more-on-interactions.html"><a href="week-13-more-on-interactions.html#pre-lab-activity-2-getting-ready-for-the-lab-class-1"><i class="fa fa-check"></i><b>4.3.2</b> Pre-lab activity 2: Getting ready for the lab class</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="week-13-more-on-interactions.html"><a href="week-13-more-on-interactions.html#lab-activities-2"><i class="fa fa-check"></i><b>4.4</b> Lab activities</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="step-5-the-regression-model.html"><a href="step-5-the-regression-model.html"><i class="fa fa-check"></i><b>5</b> Step 5: The regression model ———————–</a>
<ul>
<li class="chapter" data-level="5.1" data-path="step-5-the-regression-model.html"><a href="step-5-the-regression-model.html#answers-2"><i class="fa fa-check"></i><b>5.1</b> Answers</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analysing and Interpreting Psychological Data II - PSYC402</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="step-5-the-regression-model" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Step 5: The regression model ———————–</h1>
<p>We’ve looked at descriptive statistics and distributions of variables and also at relations between variables. This has given us a good idea of what the data look like. Now we’ll construct the regression model to predict ‘evaluation score’ as a function of ‘age’ and ‘beauty score’. We’ll do this in two stages. First we’ll construct a model without an interaction term. Then we’ll construct a model that includes an interaction term betweeen the two predictor variables. Don’t forget to use the standardised data for all this.</p>
<blockquote>
<p><strong>TASK</strong>: Construct a regression model without an interaction term. <strong>HINT</strong>: Use the following formula, lm(y ~ x1 + x2, data); go back to the research question for your outcome and predictor variables.</p>
</blockquote>
<blockquote>
<p><strong>TASK</strong>: Call and save the summary of your model; then have a look at it.</p>
</blockquote>
<p><strong>QUESTION 4</strong>: Is the overall model significant?</p>
<p><strong>QUESTION 5</strong>: Are the predictors significant? What does this mean?</p>
<blockquote>
<p><strong>TASK</strong>: Now create a model that includes an interaction term for the two predictors. Again, use the centered and standardised data. <strong>HINT</strong>: Use the following formula, lm(y ~ x1 + x2 + x1:x2, data); go back to the research question for your outcome and predictor variables.</p>
</blockquote>
<p><strong>QUESTION 6</strong>: Is the overall model significant?</p>
<p><strong>QUESTION 7</strong>: Have a good look at the coefficients. Can you interpret each one of them in turn and then formulate an overall interpretation? <strong>HINT</strong>: Remember that after centering and standardising, the meaning of 0 has changed for both predictor variables.</p>
<p>Interpretation of coefficients in a multiple regression can be facilitated by ‘added variable’ plots.</p>
<blockquote>
<p><strong>TASK</strong>: Use the function <code>avPlots()</code> to create ‘added variable’ plots.</p>
</blockquote>
<p>Creating a scatterplot with our outcome variable on the y-axis and the significant predictor on the x-axis and then plotting our third variable (age) using different colours gives some information. Do you see how high age scores (light blue + 2 SD) seem to be more frequent in the bottom left corner?</p>
<blockquote>
<p><strong>TASK</strong>: Use the code below to create the plot.</p>
</blockquote>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="step-5-the-regression-model.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> beauty_z, <span class="fu">aes</span>(<span class="at">x =</span> beauty_z, <span class="at">y =</span> eval, <span class="at">colour =</span> age_z)) <span class="sc">+</span></span>
<span id="cb21-2"><a href="step-5-the-regression-model.html#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb21-3"><a href="step-5-the-regression-model.html#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">colour =</span> <span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb21-4"><a href="step-5-the-regression-model.html#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb21-5"><a href="step-5-the-regression-model.html#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Beauty score&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Teaching evaluation score&quot;</span>)</span></code></pre></div>
<p>But it might be more useful to plot different regression lines for different values of age. We can do this be transforming age into a categorical variable for plotting purposes. The code below creates three categories, based on eye-balling the histogram for age:</p>
<ul>
<li>youngest (40 and younger)</li>
<li>average (between 41 and 53)</li>
<li>oldest (54 and older).</li>
</ul>
<blockquote>
<p><strong>TASK</strong>: Copy the code below to your script and make sure you understand what it does.</p>
</blockquote>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="step-5-the-regression-model.html#cb22-1" aria-hidden="true" tabindex="-1"></a>oldest <span class="ot">&lt;-</span> beauty_z <span class="sc">%&gt;%</span></span>
<span id="cb22-2"><a href="step-5-the-regression-model.html#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(age <span class="sc">&gt;=</span> <span class="dv">54</span>)</span>
<span id="cb22-3"><a href="step-5-the-regression-model.html#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="step-5-the-regression-model.html#cb22-4" aria-hidden="true" tabindex="-1"></a>average <span class="ot">&lt;-</span> beauty_z <span class="sc">%&gt;%</span></span>
<span id="cb22-5"><a href="step-5-the-regression-model.html#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(age <span class="sc">&gt;</span> <span class="dv">40</span>) <span class="sc">%&gt;%</span></span>
<span id="cb22-6"><a href="step-5-the-regression-model.html#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(age <span class="sc">&lt;</span> <span class="dv">54</span>)</span>
<span id="cb22-7"><a href="step-5-the-regression-model.html#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="step-5-the-regression-model.html#cb22-8" aria-hidden="true" tabindex="-1"></a>youngest <span class="ot">&lt;-</span> beauty_z <span class="sc">%&gt;%</span></span>
<span id="cb22-9"><a href="step-5-the-regression-model.html#cb22-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(age <span class="sc">&lt;=</span> <span class="dv">40</span>)</span></code></pre></div>
<p>Now let’s create a single plot with three different lines, one for each of the age groups created above.</p>
<blockquote>
<p><strong>TASK</strong>: Copy the code below to your script and make sure you understand what it does.</p>
</blockquote>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="step-5-the-regression-model.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb23-2"><a href="step-5-the-regression-model.html#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> oldest, <span class="fu">aes</span>(<span class="at">x =</span> beauty_z, <span class="at">y =</span> eval), <span class="at">colour =</span> <span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb23-3"><a href="step-5-the-regression-model.html#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data =</span> oldest, <span class="fu">aes</span>(<span class="at">x =</span> beauty_z, <span class="at">y =</span> eval), <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">colour =</span> <span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb23-4"><a href="step-5-the-regression-model.html#cb23-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> average, <span class="fu">aes</span>(<span class="at">x =</span> beauty_z, <span class="at">y =</span> eval), <span class="at">colour =</span> <span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb23-5"><a href="step-5-the-regression-model.html#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data =</span> average, <span class="fu">aes</span>(<span class="at">x =</span> beauty_z, <span class="at">y =</span> eval), <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">colour =</span> <span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb23-6"><a href="step-5-the-regression-model.html#cb23-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> youngest, <span class="fu">aes</span>(<span class="at">x =</span> beauty_z, <span class="at">y =</span> eval), <span class="at">colour =</span> <span class="st">&#39;green&#39;</span>) <span class="sc">+</span></span>
<span id="cb23-7"><a href="step-5-the-regression-model.html#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data =</span> youngest, <span class="fu">aes</span>(<span class="at">x =</span> beauty_z, <span class="at">y =</span> eval), <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">colour =</span> <span class="st">&#39;green&#39;</span>) <span class="sc">+</span></span>
<span id="cb23-8"><a href="step-5-the-regression-model.html#cb23-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb23-9"><a href="step-5-the-regression-model.html#cb23-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Beauty score&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Teaching evaluation score&quot;</span>)</span></code></pre></div>
<p>The line for the oldest participants seems much steeper than for the other two groups, suggesting that the interaction between age and beauty is mostly driven by older participants who have received more extreme beauty scores.</p>
<div id="step-6-checking-assumptions" class="section level4" number="5.0.0.1">
<h4><span class="header-section-number">5.0.0.1</span> Step 6: Checking assumptions —————–</h4>
<p>Now that we’ve fitted a model, let’s check whether it meets the assumptions of linearity, normality and homoscedasticity.</p>
<p><strong>Linearity</strong>
Unlike when we did simple regression we can’t use <code>crPlots()</code> to test for linearity when there is an interaction, but we know from looking at the grouped scatterplot that this assumption has been met.</p>
<p><strong>Normality</strong>
Normally we would test for normality with a qq-plot and a Shapiro-Wilk test. However, because this dataset is so large, the Shapiro-Wilk is not appropriate (if you try to run the test it will produce a warning telling you that the sample size must be between 3 and 5000). This is because with extremely large sample sizes the Shapiro-Wilk test will find that any deviation from normality is significant. Therefore we should judge normality based upon the qq-plot.</p>
<blockquote>
<p><strong>TASK</strong>: Create a qq-plot to check the residuals are normally distributed. <strong>HINT</strong>: Use the <code>qqPlot()</code> function; mind the capital P.</p>
</blockquote>
<p><strong>QUESTION 8</strong>: What do you conclude from the qq-plot?
# ANSWER: The residuals are normally distributed.</p>
<p><strong>Homoscedasticity</strong>
Here we have the same problem as with testing for normality: with such a large sample the <code>ncvTest()</code> will produce a significant result for any deviation from homoscedasticity. So we need to rely on plots again.</p>
<p>To check for homoscedasticity we can use <code>plot()</code> from Base R that will produce a bunch of helpful plots (more information [<strong>here</strong>] (<a href="https://www.r-bloggers.com/2016/01/how-to-detect-heteroscedasticity-and-rectify-it/" class="uri">https://www.r-bloggers.com/2016/01/how-to-detect-heteroscedasticity-and-rectify-it/</a>).</p>
<blockquote>
<p><strong>TASK</strong>: Copy the code below to your script and run it to create the plots</p>
</blockquote>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="step-5-the-regression-model.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))                 <span class="co"># 4 charts in 1 panel</span></span>
<span id="cb24-2"><a href="step-5-the-regression-model.html#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod_int)                     <span class="co"># this may take a few seconds to run</span></span></code></pre></div>
<p><strong>QUESTION 9</strong>: What do you conclude from the residuals vs leverage plot?</p>
<p><strong>Mulit-collinearity</strong>
Now let’s check for multi-collinearity using the <code>vif()</code> function. Essentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor isn’t actually adding any unique variance to the model, it’s just really strongly related to other predictors. Thankfully, the <code>vif()</code> function is not affected by large samples like the other tests. There are various rules of thumb, but most converge on a VIF of above 2 - 2.5 for any one predictor being problematic.</p>
<blockquote>
<p><strong>TASK</strong>: Use the <code>vif()</code> function to test for multi-collinearity.</p>
</blockquote>
<p><strong>QUESTION 10</strong>: Do any of the predictors show evidence of multi-collinearity?</p>
<p>Finally, we need to write up the results.</p>
<p><strong>QUESTION 11</strong>: Can you write up the results of the regression analysis following APA guidelines? <strong>HINT</strong>: Don’t forget to mention and interpret the interaction effect.</p>
</div>
<div id="answers-2" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Answers</h2>
<p>When you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. <strong>Remember</strong>, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. <strong>Actively engaging</strong> with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…</p>
<p>The answers to the questions and the script containing the code will be available after the lab session has taken place.</p>
<!-- You can download the R-script that includes the relevant code here: [402_wk13_labAct1_withAnswers.R](files/week13/402_wk13_labAct1_withAnswers.R). -->
<ol style="list-style-type: decimal">
<li><p>Do you notice anything about the name of one of the variables and the name of the data table? <strong>Both the data table and one of the variables are called ‘beauty’. Not a problem, as such as long as you don’t get confused.</strong></p></li>
<li><p>Can you write an interpretation of the above plots in plain English?</p></li>
</ol>
<p><strong>POSSIBLE ANSWER:</strong></p>
<ul>
<li>A moderate negative association seems present between beauty score and age: with increasing age, beauty score decreases.</li>
<li>A moderate positive association seems present between beauty score and teaching evaluation: professors with higher beauty scores also receive higher teaching evaluations.</li>
<li>Not much of a association seems present between age and teaching evaluation (the line is pretty horizontal).</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>What is the difference between the scatterplots plotting the raw data and the ones plotting the centered and standardised data? <strong>The units of the x-axis have changed from years (for age) and scores (for beauty) to standard units, with zero in the middle.</strong></p></li>
<li><p>Is the overall model significant? <strong>Yes, <em>F</em>(2, 460) = 8.53, <em>p</em> = .0002</strong></p></li>
<li><p>Are the predictors significant? What does this mean? <strong>The beauty score significantly predicts teaching evaluation score, but age does not. Professors with higher beauty scores, received better teaching evaluations.</strong></p></li>
<li><p>Is the overall model significant? <strong>Yes, <em>F</em>(3, 459) = 9.32, <em>p</em> = 5.451e-06</strong></p></li>
<li><p>Have a good look at the coefficients. Can you interpret each one of them in turn and then formulate an overall interpretation? <strong>HINT</strong>: Remember that after centering and standardising, the meaning of 0 has changed for both predictor variables.</p></li>
</ol>
<p><strong>The intercept is predicted teaching evaluation score for a professor with average age and average beauty score.</strong></p>
<p><strong>The slope of ‘age’ is positive; this means that for higher age, teaching evaluation scores
were better. However the coefficient is not significant, therefore has little predictive
power.</strong></p>
<p><strong>The slope of ‘beauty’ is positive; this means that with higher beauty score, professors receive higher teaching evaluations. This predictor is significant.</strong></p>
<p><strong>The slope for the interaction is also positive. This can be read as follows: When age and beauty both increase, teaching evaluation score also increases. The interaction is significant.</strong></p>
<ol start="8" style="list-style-type: decimal">
<li><p>What do you conclude from the qq-plot? <strong>The residuals are normally distributed.</strong></p></li>
<li><p><strong>QUESTION 9</strong>: What do you conclude from the residuals vs leverage plot? **The residuals vs leverage plot shows a flat red line so, whilst it isn’t perfect, we can assume that with regression is still an appropriate analysis.</p></li>
<li><p>Do any of the predictors show evidence of multi-collinearity? <strong>No</strong></p></li>
<li><p>Can you write up the results of the regression analysis following APA guidelines? <strong>The results of the regression indicated that the model significantly predicted teaching evaluation scores (<em>F</em>(3, 459) = 9.316, <em>p</em> &lt; .001, Adjusted <em>R^2</em> = 0.05), accounting for 5% of the variance. A professor’s beauty score was a significant positive predictor of teaching evaluation score (beta = 0.12, <em>p</em> &lt; .001). This effect was moderated by a significant positive interaction between beauty score and age (beta = 0.08, <em>p</em> &lt; .001), suggesting that when age and beauty score both increased, teaching evaluation score also increased.</strong></p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="week-13-more-on-interactions.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-start.pdf", "bookdown-start.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
